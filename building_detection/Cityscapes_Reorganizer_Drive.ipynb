{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "963fe200",
      "metadata": {
        "id": "963fe200"
      },
      "source": [
        "# Cityscapes gtFine Reorganizer - Local Edition\n",
        "\n",
        "This notebook reorganizes your existing Cityscapes gtFine dataset from a local folder:\n",
        "\n",
        "**Current structure:**\n",
        "```\n",
        "gtFine/\n",
        "â”œâ”€â”€ train/berlin/, train/bonn/, etc.\n",
        "â”œâ”€â”€ val/berlin/, val/munich/, etc.\n",
        "â””â”€â”€ test/berlin/, test/bielefeld/, etc.\n",
        "```\n",
        "\n",
        "**Target structure:**\n",
        "```\n",
        "reorganized_cityscapes/\n",
        "â””â”€â”€ gtFine/\n",
        "    â”œâ”€â”€ train/building/, train/non_building/\n",
        "    â”œâ”€â”€ val/building/, val/non_building/\n",
        "    â””â”€â”€ test/building/, test/non_building/\n",
        "```\n",
        "\n",
        "This will reorganize only the gtFine annotation files (no RGB images needed)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4823bc2",
      "metadata": {
        "id": "f4823bc2"
      },
      "source": [
        "## Step 1: Configure Local Paths and Locate Your Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "372f25b0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "372f25b0",
        "outputId": "3b056ee1-023f-4960-8c7a-b769e928f65e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "âœ… Google Drive mounted!\n",
            "ğŸ“ gtFine path: /content/drive/MyDrive/gtFine\n",
            "ğŸ’¾ Output path: /content/drive/MyDrive/reorganized_cityscapes\n",
            "\n",
            "ğŸ” Checking your data...\n",
            "âœ… Found gtFine directory\n",
            "   Splits found: ['train', 'val', 'test']\n"
          ]
        }
      ],
      "source": [
        "# Configure local paths\n",
        "import os\n",
        "\n",
        "# Path configuration - update these to match your local directory structure\n",
        "# Example: GTFINE_PATH = \"/path/to/your/gtFine\"\n",
        "#          OUTPUT_PATH = \"/path/to/your/reorganized_cityscapes\"\n",
        "GTFINE_PATH = \"./gtFine\"  # Update this to your gtFine directory path\n",
        "OUTPUT_PATH = \"./reorganized_cityscapes\"  # Update this to your desired output directory\n",
        "\n",
        "print(\"âœ… Path configuration loaded!\")\n",
        "print(f\"ğŸ“ gtFine path: {GTFINE_PATH}\")\n",
        "print(f\"ğŸ’¾ Output path: {OUTPUT_PATH}\")\n",
        "\n",
        "# Verify your data exists\n",
        "print(\"\\nğŸ” Checking your data...\")\n",
        "if os.path.exists(GTFINE_PATH):\n",
        "    print(f\"âœ… Found gtFine directory\")\n",
        "    splits = [d for d in os.listdir(GTFINE_PATH) if os.path.isdir(os.path.join(GTFINE_PATH, d))]\n",
        "    print(f\"   Splits found: {splits}\")\n",
        "else:\n",
        "    print(f\"âŒ gtFine directory not found at {GTFINE_PATH}\")\n",
        "    print(f\"   Please update GTFINE_PATH in the cell above to point to your gtFine directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82f9d18f",
      "metadata": {
        "id": "82f9d18f"
      },
      "source": [
        "## Step 2: Preview Current Structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93a125a7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93a125a7",
        "outputId": "fa85b7bd-fdec-432b-878b-9f7d286911a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current dataset structure:\n",
            "==================================================\n",
            "\n",
            "ğŸ“ gtFine/train/\n",
            "   Cities: ['aachen', 'cologne', 'bochum', 'darmstadt', 'bremen']... (18 total)\n",
            "   Total images: 2975\n",
            "\n",
            "ğŸ“ gtFine/val/\n",
            "   Cities: ['lindau', 'frankfurt', 'munster'] (3 total)\n",
            "   Total images: 500\n",
            "\n",
            "ğŸ“ gtFine/test/\n",
            "   Cities: ['berlin', 'bonn', 'leverkusen', 'mainz', 'bielefeld']... (6 total)\n",
            "   Total images: 1525\n",
            "\n",
            "ğŸ¯ After reorganization:\n",
            "Each split will have only 2 directories:\n",
            "   â”œâ”€â”€ building/     (images containing buildings)\n",
            "   â””â”€â”€ non_building/ (images without buildings)\n"
          ]
        }
      ],
      "source": [
        "# Preview your current dataset structure\n",
        "print(\"Current dataset structure:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "for split in ['train', 'val', 'test']:\n",
        "    gtfine_split_path = os.path.join(GTFINE_PATH, split)\n",
        "    if os.path.exists(gtfine_split_path):\n",
        "        cities = [d for d in os.listdir(gtfine_split_path)\n",
        "                 if os.path.isdir(os.path.join(gtfine_split_path, d))]\n",
        "        print(f\"\\nğŸ“ gtFine/{split}/\")\n",
        "        print(f\"   Cities: {cities[:5]}{'...' if len(cities) > 5 else ''} ({len(cities)} total)\")\n",
        "\n",
        "        # Count total images in this split\n",
        "        total_images = 0\n",
        "        for city in cities:\n",
        "            city_path = os.path.join(gtfine_split_path, city)\n",
        "            json_files = [f for f in os.listdir(city_path) if f.endswith('_polygons.json')]\n",
        "            total_images += len(json_files)\n",
        "        print(f\"   Total images: {total_images}\")\n",
        "\n",
        "print(\"\\nğŸ¯ After reorganization:\")\n",
        "print(\"Each split will have only 2 directories:\")\n",
        "print(\"   â”œâ”€â”€ building/     (images containing buildings)\")\n",
        "print(\"   â””â”€â”€ non_building/ (images without buildings)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d736f1ab",
      "metadata": {
        "id": "d736f1ab"
      },
      "source": [
        "## Step 3: Building Detection and Reorganization Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2530bf2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2530bf2",
        "outputId": "5e0daeb0-7a56-4a69-88b5-8d456a58a3fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… gtFine reorganization functions loaded!\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import glob\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "def has_building_annotation(annotation_file):\n",
        "    \"\"\"\n",
        "    Check if an annotation file contains building objects.\n",
        "\n",
        "    Args:\n",
        "        annotation_file (str): Path to the JSON annotation file\n",
        "\n",
        "    Returns:\n",
        "        bool: True if the image contains buildings, False otherwise\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(annotation_file, 'r') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        # Check if any object in the annotation is a building\n",
        "        objects = data.get('objects', [])\n",
        "        for obj in objects:\n",
        "            if obj.get('label') == 'building':\n",
        "                return True\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Could not process {annotation_file}: {e}\")\n",
        "        return False\n",
        "\n",
        "def get_base_name_from_annotation(annotation_file):\n",
        "    \"\"\"Extract base name from annotation filename.\"\"\"\n",
        "    base_name = os.path.basename(annotation_file)\n",
        "    if '_gtFine_polygons.json' in base_name:\n",
        "        return base_name.replace('_gtFine_polygons.json', '')\n",
        "    elif '_gtCoarse_polygons.json' in base_name:\n",
        "        return base_name.replace('_gtCoarse_polygons.json', '')\n",
        "    return base_name\n",
        "\n",
        "def find_gtfine_files(base_name, gtfine_path, split):\n",
        "    \"\"\"\n",
        "    Find all gtFine files related to a base image name.\n",
        "\n",
        "    Args:\n",
        "        base_name (str): Base name like \"city_123456_123456\"\n",
        "        gtfine_path (str): Path to gtFine data\n",
        "        split (str): Split name (train, val, test)\n",
        "\n",
        "    Returns:\n",
        "        list: List of gtFine file paths\n",
        "    \"\"\"\n",
        "    files = []\n",
        "    city = base_name.split('_')[0]\n",
        "\n",
        "    # gtFine files\n",
        "    gtfine_city_path = os.path.join(gtfine_path, split, city)\n",
        "    if os.path.exists(gtfine_city_path):\n",
        "        gtfine_patterns = [\n",
        "            f\"{base_name}_gtFine_color.png\",\n",
        "            f\"{base_name}_gtFine_instanceIds.png\",\n",
        "            f\"{base_name}_gtFine_labelIds.png\",\n",
        "            f\"{base_name}_gtFine_polygons.json\"\n",
        "        ]\n",
        "        for pattern in gtfine_patterns:\n",
        "            file_path = os.path.join(gtfine_city_path, pattern)\n",
        "            if os.path.exists(file_path):\n",
        "                files.append(file_path)\n",
        "\n",
        "    return files\n",
        "\n",
        "def copy_gtfine_files(file_paths, output_path, split, category):\n",
        "    \"\"\"\n",
        "    Copy gtFine files to the new building-based directory structure.\n",
        "\n",
        "    Args:\n",
        "        file_paths (list): List of gtFine file paths\n",
        "        output_path (str): Output directory path\n",
        "        split (str): Split name\n",
        "        category (str): 'building' or 'non_building'\n",
        "    \"\"\"\n",
        "    # Create new directory structure\n",
        "    new_dir = os.path.join(output_path, 'gtFine', split, category)\n",
        "    os.makedirs(new_dir, exist_ok=True)\n",
        "\n",
        "    for file_path in file_paths:\n",
        "        new_file_path = os.path.join(new_dir, os.path.basename(file_path))\n",
        "        try:\n",
        "            shutil.copy2(file_path, new_file_path)\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not copy {file_path}: {e}\")\n",
        "\n",
        "print(\"âœ… gtFine reorganization functions loaded!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0aa8c2d",
      "metadata": {
        "id": "e0aa8c2d"
      },
      "source": [
        "## Step 4: Run the Reorganization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79284a02",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "79284a02",
        "outputId": "f388530f-3c5f-4706-8a6e-af4c2e636ab6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting gtFine reorganization... This may take several minutes!\n",
            "ğŸš€ Starting gtFine dataset reorganization...\n",
            "ğŸ“‚ gtFine source: /content/drive/MyDrive/gtFine\n",
            "ğŸ’¾ Output: /content/drive/MyDrive/reorganized_cityscapes\n",
            "ğŸ“‹ Splits: train, val, test\n",
            "\n",
            "ğŸ”„ Processing split: train\n",
            "  ğŸ“„ Found 2975 annotation files\n",
            "    âœ… Processed 100/2975 files...\n",
            "    âœ… Processed 200/2975 files...\n",
            "    âœ… Processed 300/2975 files...\n",
            "    âœ… Processed 400/2975 files...\n",
            "    âœ… Processed 500/2975 files...\n",
            "    âœ… Processed 600/2975 files...\n",
            "    âœ… Processed 700/2975 files...\n",
            "    âœ… Processed 800/2975 files...\n",
            "    âœ… Processed 900/2975 files...\n",
            "    âœ… Processed 1000/2975 files...\n",
            "    âœ… Processed 1100/2975 files...\n",
            "    âœ… Processed 1200/2975 files...\n",
            "    âœ… Processed 1300/2975 files...\n",
            "    âœ… Processed 1400/2975 files...\n",
            "    âœ… Processed 1500/2975 files...\n",
            "    âœ… Processed 1600/2975 files...\n",
            "    âœ… Processed 1700/2975 files...\n",
            "    âœ… Processed 1800/2975 files...\n",
            "    âœ… Processed 1900/2975 files...\n",
            "    âœ… Processed 2000/2975 files...\n",
            "    âœ… Processed 2100/2975 files...\n",
            "    âœ… Processed 2200/2975 files...\n",
            "    âœ… Processed 2300/2975 files...\n",
            "    âœ… Processed 2400/2975 files...\n",
            "    âœ… Processed 2500/2975 files...\n",
            "    âœ… Processed 2600/2975 files...\n",
            "    âœ… Processed 2700/2975 files...\n",
            "    âœ… Processed 2800/2975 files...\n",
            "    âœ… Processed 2900/2975 files...\n",
            "\n",
            "ğŸ”„ Processing split: val\n",
            "  ğŸ“„ Found 500 annotation files\n",
            "    âœ… Processed 100/500 files...\n",
            "    âœ… Processed 200/500 files...\n",
            "    âœ… Processed 300/500 files...\n",
            "    âœ… Processed 400/500 files...\n",
            "    âœ… Processed 500/500 files...\n",
            "\n",
            "ğŸ”„ Processing split: test\n",
            "  ğŸ“„ Found 1525 annotation files\n",
            "    âœ… Processed 100/1525 files...\n",
            "    âœ… Processed 200/1525 files...\n",
            "    âœ… Processed 300/1525 files...\n",
            "    âœ… Processed 400/1525 files...\n",
            "    âœ… Processed 500/1525 files...\n",
            "    âœ… Processed 600/1525 files...\n",
            "    âœ… Processed 700/1525 files...\n",
            "    âœ… Processed 800/1525 files...\n",
            "    âœ… Processed 900/1525 files...\n",
            "    âœ… Processed 1000/1525 files...\n",
            "    âœ… Processed 1100/1525 files...\n",
            "    âœ… Processed 1200/1525 files...\n",
            "    âœ… Processed 1300/1525 files...\n",
            "    âœ… Processed 1400/1525 files...\n",
            "    âœ… Processed 1500/1525 files...\n",
            "\n",
            "ğŸ‰ gtFine reorganization complete!\n",
            "ğŸ“Š Results:\n",
            "   ğŸ¢ Building images: 3425\n",
            "   ğŸŒ† Non-building images: 1575\n",
            "   ğŸ“ Total processed: 5000\n",
            "   ğŸ’¾ Output saved to: /content/drive/MyDrive/reorganized_cityscapes\n"
          ]
        }
      ],
      "source": [
        "# Main reorganization function for gtFine only\n",
        "def reorganize_gtfine_dataset(gtfine_path, output_path, splits=['train', 'val', 'test']):\n",
        "    \"\"\"\n",
        "    Reorganize the Cityscapes gtFine dataset by building content.\n",
        "\n",
        "    Args:\n",
        "        gtfine_path (str): Path to gtFine data\n",
        "        output_path (str): Output directory\n",
        "        splits (list): List of splits to process\n",
        "    \"\"\"\n",
        "    print(f\"ğŸš€ Starting gtFine dataset reorganization...\")\n",
        "    print(f\"ğŸ“‚ gtFine source: {gtfine_path}\")\n",
        "    print(f\"ğŸ’¾ Output: {output_path}\")\n",
        "    print(f\"ğŸ“‹ Splits: {', '.join(splits)}\")\n",
        "\n",
        "    # Create output directory\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "    building_count = 0\n",
        "    non_building_count = 0\n",
        "    total_processed = 0\n",
        "\n",
        "    for split in splits:\n",
        "        print(f\"\\nğŸ”„ Processing split: {split}\")\n",
        "\n",
        "        # Find all annotation files in this split\n",
        "        annotation_pattern = os.path.join(gtfine_path, split, '*', '*_gtFine_polygons.json')\n",
        "        annotation_files = glob.glob(annotation_pattern)\n",
        "\n",
        "        if not annotation_files:\n",
        "            print(f\"  âš ï¸ No annotation files found for split {split}\")\n",
        "            continue\n",
        "\n",
        "        annotation_files.sort()\n",
        "        print(f\"  ğŸ“„ Found {len(annotation_files)} annotation files\")\n",
        "\n",
        "        for i, annotation_file in enumerate(annotation_files):\n",
        "            total_processed += 1\n",
        "\n",
        "            # Extract base name\n",
        "            base_name = get_base_name_from_annotation(annotation_file)\n",
        "\n",
        "            # Check if image has building annotations\n",
        "            has_buildings = has_building_annotation(annotation_file)\n",
        "            category = 'building' if has_buildings else 'non_building'\n",
        "\n",
        "            if has_buildings:\n",
        "                building_count += 1\n",
        "            else:\n",
        "                non_building_count += 1\n",
        "\n",
        "            # Find all related gtFine files for this base name\n",
        "            gtfine_files = find_gtfine_files(base_name, gtfine_path, split)\n",
        "\n",
        "            if gtfine_files:\n",
        "                copy_gtfine_files(gtfine_files, output_path, split, category)\n",
        "\n",
        "            # Progress update\n",
        "            if (i + 1) % 100 == 0:\n",
        "                print(f\"    âœ… Processed {i + 1}/{len(annotation_files)} files...\")\n",
        "\n",
        "    print(f\"\\nğŸ‰ gtFine reorganization complete!\")\n",
        "    print(f\"ğŸ“Š Results:\")\n",
        "    print(f\"   ğŸ¢ Building images: {building_count}\")\n",
        "    print(f\"   ğŸŒ† Non-building images: {non_building_count}\")\n",
        "    print(f\"   ğŸ“ Total processed: {total_processed}\")\n",
        "    print(f\"   ğŸ’¾ Output saved to: {output_path}\")\n",
        "\n",
        "    return building_count, non_building_count\n",
        "\n",
        "# Run the reorganization\n",
        "print(\"Starting gtFine reorganization... This may take several minutes!\")\n",
        "building_count, non_building_count = reorganize_gtfine_dataset(\n",
        "    gtfine_path=GTFINE_PATH,\n",
        "    output_path=OUTPUT_PATH\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82e71e98",
      "metadata": {
        "id": "82e71e98"
      },
      "source": [
        "## Step 5: Verify the New Structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53c0f369",
      "metadata": {
        "id": "53c0f369"
      },
      "outputs": [],
      "source": [
        "# Verify the new gtFine structure\n",
        "print(\"ğŸ” Verifying new gtFine dataset structure:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Check gtFine structure\n",
        "gtfine_path = os.path.join(OUTPUT_PATH, 'gtFine')\n",
        "if os.path.exists(gtfine_path):\n",
        "    print(f\"\\nğŸ“ gtFine/\")\n",
        "\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        split_path = os.path.join(gtfine_path, split)\n",
        "        if os.path.exists(split_path):\n",
        "            print(f\"  ğŸ“‚ {split}/\")\n",
        "\n",
        "            # Count files in building directory\n",
        "            building_path = os.path.join(split_path, 'building')\n",
        "            if os.path.exists(building_path):\n",
        "                building_files = len([f for f in os.listdir(building_path)])\n",
        "                print(f\"    ğŸ¢ building/: {building_files} files\")\n",
        "\n",
        "            # Count files in non_building directory\n",
        "            non_building_path = os.path.join(split_path, 'non_building')\n",
        "            if os.path.exists(non_building_path):\n",
        "                non_building_files = len([f for f in os.listdir(non_building_path)])\n",
        "                print(f\"    ğŸŒ† non_building/: {non_building_files} files\")\n",
        "        else:\n",
        "            print(f\"  ğŸ“‚ {split}/: Not found\")\n",
        "else:\n",
        "    print(f\"\\nğŸ“ gtFine/: Not found\")\n",
        "\n",
        "# Show sample files\n",
        "print(f\"\\nğŸ“„ Sample files in reorganized structure:\")\n",
        "sample_building_path = os.path.join(OUTPUT_PATH, 'gtFine', 'train', 'building')\n",
        "if os.path.exists(sample_building_path):\n",
        "    sample_files = os.listdir(sample_building_path)[:5]\n",
        "    for file in sample_files:\n",
        "        print(f\"  ğŸ¢ {file}\")\n",
        "\n",
        "sample_non_building_path = os.path.join(OUTPUT_PATH, 'gtFine', 'train', 'non_building')\n",
        "if os.path.exists(sample_non_building_path):\n",
        "    sample_files = os.listdir(sample_non_building_path)[:5]\n",
        "    for file in sample_files:\n",
        "        print(f\"  ğŸŒ† {file}\")\n",
        "\n",
        "print(f\"\\nâœ… gtFine reorganization verification complete!\")\n",
        "print(f\"ğŸ“ Your new gtFine dataset is available at: {OUTPUT_PATH}/gtFine\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c5c401e",
      "metadata": {
        "id": "1c5c401e"
      },
      "source": [
        "## Step 6: Summary and Next Steps\n",
        "\n",
        "ğŸ‰ **Congratulations!** Your Cityscapes gtFine dataset has been successfully reorganized!\n",
        "\n",
        "### What was accomplished:\n",
        "- âœ… Analyzed all gtFine annotation files to detect building content\n",
        "- âœ… Reorganized from city-based to building-based directory structure  \n",
        "- âœ… Preserved all gtFine file relationships (annotations, labels, instances)\n",
        "- âœ… Created simple 2-directory structure under each split\n",
        "\n",
        "### Your new gtFine dataset structure:\n",
        "```\n",
        "reorganized_cityscapes/\n",
        "â””â”€â”€ gtFine/\n",
        "    â”œâ”€â”€ train/building/ & train/non_building/\n",
        "    â”œâ”€â”€ val/building/ & val/non_building/\n",
        "    â””â”€â”€ test/building/ & test/non_building/\n",
        "```\n",
        "\n",
        "### File types included:\n",
        "- `*_gtFine_color.png` - Colored label images\n",
        "- `*_gtFine_instanceIds.png` - Instance segmentation masks\n",
        "- `*_gtFine_labelIds.png` - Label ID images\n",
        "- `*_gtFine_polygons.json` - Polygon annotations\n",
        "\n",
        "### Next steps:\n",
        "1. **Use for training**: Load `building/` directories for building-focused models\n",
        "2. **Annotation analysis**: Analyze building vs non-building annotation patterns\n",
        "3. **Data loading**: Simplified data loading with only 2 categories per split\n",
        "4. **Model development**: Train specialized models on building vs non-building annotations\n",
        "\n",
        "Your reorganized gtFine dataset is now saved locally and ready for use! ğŸš€"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
